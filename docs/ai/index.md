# 人工智能

## 资源

[huggingface](https://huggingface.co/): 是一个自然语言处理（NLP）模型和数据集的开源社区平台。它提供了一个集成了各种NLP模型和数据集的中央存储库，用户可以在平台上访问和使用这些模型和数据集。此外，Hugging Face还提供了一个名为Transformers的Python库，它包含了各种预训练的NLP模型，例如BERT、GPT-2等，可以用于各种NLP任务，例如文本分类、命名实体识别、问答等。Hugging Face还提供了一些工具和API，使得用户可以轻松地使用这些模型和数据集来构建自己的NLP应用程序。

[Zenodo](https://zenodo.org/): Zenodo是一个开放式数字存储库，旨在为研究人员、科学家、教育家和其他学术界人士提供一个免费、安全、可靠的平台，用于存储、共享和发现科学研究成果。Zenodo由欧洲核子研究组织（CERN）开发和维护，它允许用户上传和存储各种类型的研究成果，包括数据集、软件、出版物、演示文稿等。Zenodo的目标是促进科学研究成果的共享和可持续性，并为全球科学社区提供一个开放、透明和可访问的平台。

## 模型

[ChatGLM-6b](https://github.com/THUDM/ChatGLM-6B): ChatGLM-6B 是一个开源的、支持中英双语的对话语言模型，基于 General Language Model (GLM) 架构，具有 62 亿参数。结合模型量化技术，用户可以在消费级的显卡上进行本地部署（INT4 量化级别下最低只需 6GB 显存）。 ChatGLM-6B 使用了和 ChatGPT 相似的技术，针对中文问答和对话进行了优化。经过约 1T 标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62 亿参数的 ChatGLM-6B 已经能生成相当符合人类偏好的回答。

[ChatGLM-130b](https://github.com/THUDM/GLM-130B): 是一个开源开放的双语（中文和英文）双向稠密模型，拥有 1300 亿参数，模型架构采用通用语言模型（GLM1）。它旨在支持在一台 A100（40G x 8）或 V100（32G x 8）服务器上对千亿规模参数的模型进行推理。

[llama](https://github.com/facebookresearch/llama)

[vicuna](https://lmsys.org/blog/2023-03-30-vicuna/)

## 工具

[LoRA: Low-Rank Adaptation of Large Language Models](https://github.com/microsoft/LoRA): an implementation of "LoRA: Low-Rank Adaptation of Large Language Models"

[DeepSpeed](https://github.com/microsoft/DeepSpeed)DeepSpeed 是一个深度学习优化库，它使分布式训练和推理变得简单、高效和有效。
